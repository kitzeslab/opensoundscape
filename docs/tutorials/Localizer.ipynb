{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas \n",
    "import opensoundscape\n",
    "from opensoundscape.audio import Audio\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.signal import correlate, correlation_lags\n",
    "import statsmodels.api as sm\n",
    "\n",
    "def gcc(x, y, max_delay_samples=None, filter=\"phat\", epsilon=0.01):\n",
    "    \"\"\"\n",
    "    GCC implementation based on Knapp and Carter - code adapted from\n",
    "    github.com/axeber01/ngcc\n",
    "    Args:\n",
    "        x: 1d numpy array of audio samples\n",
    "        y: 1d numpy array of audio samples\n",
    "        max_delay_samples: maximum possible delay between the 2 signals in max_delay_samples\n",
    "        filter: which filter to use in the gcc.\n",
    "            'phat' - Phase transform,\n",
    "            'roth',\n",
    "            'scot' - Smoothed Coherence Transform,\n",
    "            'ht' - Hannan and Thomson\n",
    "        epsilon = used to ensure denominator is non-zero.\n",
    "    \"\"\"\n",
    "    n = x.shape[0] + y.shape[0]\n",
    "\n",
    "    # Generalized Cross Correlation Phase Transform\n",
    "    X = np.fft.rfft(x, n=n)\n",
    "    Y = np.fft.rfft(y, n=n)\n",
    "    Gxy = X * np.conj(Y)\n",
    "\n",
    "    if filter == \"phat\":\n",
    "        phi = 1 / (np.abs(Gxy) + epsilon)\n",
    "\n",
    "    elif filter == \"roth\":\n",
    "        phi = 1 / (X * torch.conj(X) + epsilon)\n",
    "\n",
    "    elif filter == \"scot\":\n",
    "        Gxx = X * np.conj(X)\n",
    "        Gyy = Y * np.conj(Y)\n",
    "        phi = 1 / (np.sqrt(X * Y) + epsilon)\n",
    "\n",
    "    elif filter == \"ht\":\n",
    "        Gxx = X * np.conj(X)\n",
    "        Gyy = Y * np.conj(Y)\n",
    "        gamma = Gxy / np.sqrt(Gxx * Gxy)\n",
    "        phi = np.abs(gamma) ** 2 / (np.abs(Gxy) * (1 - gamma) ** 2 + epsilon)\n",
    "    elif filter == \"cc\":\n",
    "        phi = 1.0\n",
    "    else:\n",
    "        raise ValueError(\n",
    "            \"Unsupported filter. Must be one of: 'ht', 'phat', 'roth','scot'\"\n",
    "        )\n",
    "\n",
    "    # set the max delay in number of samples\n",
    "    if max_delay_samples:\n",
    "        max_delay_samples = np.minimum(max_delay_samples, int(n / 2))\n",
    "    else:\n",
    "        max_delay_samples = int(n / 2)\n",
    "\n",
    "    cc = np.fft.irfft(Gxy * phi, n)\n",
    "\n",
    "    return cc\n",
    "\n",
    "\n",
    "# make a class that we will use to contain a model object, list of files and thresholds\n",
    "# this will be called Localizer\n",
    "# we will use this class for localizing sound sources from synchronized audio files\n",
    "class Localizer:\n",
    "    def __init__(\n",
    "        self,\n",
    "        model,\n",
    "        files,\n",
    "        aru_coords,\n",
    "        sample_rate,\n",
    "        min_number_of_receivers,\n",
    "        max_distance_between_receivers,\n",
    "        thresholds=None,\n",
    "        predictions=None,\n",
    "        bandpass_ranges=None,\n",
    "        max_delay=None,\n",
    "        cc_threshold=0,\n",
    "    ):\n",
    "        # initialize the class\n",
    "        # model is a trained opensoundscape model\n",
    "        # files is a list of synchronized audio files\n",
    "        # aru_coords is a dictionary of aru coordinates, with key aru file path, and value (x,y) coordinates\n",
    "        # thresholds is a dictionary of thresholds for each class\n",
    "        # predictions is a pandas dataframe of predictions\n",
    "        self.model = model\n",
    "        self.files = files\n",
    "        self.aru_coords = aru_coords\n",
    "        self.thresholds = thresholds\n",
    "        self.SAMPLE_RATE = sample_rate\n",
    "        self.min_number_of_receivers = min_number_of_receivers\n",
    "        self.max_distance_between_receivers = max_distance_between_receivers\n",
    "        self.predictions = predictions\n",
    "        self.bandpass_ranges = bandpass_ranges\n",
    "        self.max_delay = max_delay\n",
    "        self.cc_threshold = cc_threshold\n",
    "\n",
    "        # initialize the below intermediates as None. #TODO: work out how to do this correctly\n",
    "        self.detections = None\n",
    "        self.cross_correlations = None\n",
    "        self.filtered_cross_correlations = None\n",
    "\n",
    "    def get_predictions(self):\n",
    "        # get CNN predictions from synchronized audio files\n",
    "        # return a pandas dataframe with the results\n",
    "        if self.predictions is None:\n",
    "            self.predictions = self.model.predict(self.files, activation_layer=None)\n",
    "        else:\n",
    "            raise UserWarning(\n",
    "                \"Predictions already exist - set predictions to None if you want to re-run predictions\"\n",
    "            )\n",
    "        return self.predictions\n",
    "\n",
    "    def threshold_predictions(self):\n",
    "        # use a set of thresholds to filter the predictions\n",
    "        if self.predictions is None:\n",
    "            print(\"No predictions exist - running predictions\")\n",
    "            self.get_predictions()\n",
    "        all_sp_detections = []\n",
    "        for species in self.predictions.columns:\n",
    "            df = self.predictions.loc[:, [species]]  # must be a dataframe\n",
    "            detections = Localizer._get_detections(\n",
    "                df, cnn_score_threshold=self.thresholds[species]\n",
    "            )\n",
    "            grouped_detections = Localizer._group_detections(\n",
    "                detections, self.aru_coords, self.min_number_of_receivers, self.max_distance_between_receivers\n",
    "            )\n",
    "            grouped_detections[\"species\"] = species\n",
    "            all_sp_detections.append(grouped_detections)\n",
    "        detections_df = pandas.concat(all_sp_detections)\n",
    "        self.detections = detections_df\n",
    "        return detections_df\n",
    "\n",
    "    def cross_correlate(self):\n",
    "        # cross correlate the predictions\n",
    "        # return a pandas dataframe with the results\n",
    "        if self.bandpass_ranges is None:\n",
    "            raise UserWarning(\"No bandpass range specified\")\n",
    "        if self.max_delay is None:\n",
    "            raise UserWarning(\"No max delay specified\")\n",
    "        if self.detections is None:\n",
    "            print(\"No detections exist - running threshold_predictions\")\n",
    "            self.threshold_predictions()\n",
    "        # get the cross-correlations\n",
    "        all_ccs = []\n",
    "        all_tds = []\n",
    "        for index, row in self.detections.iterrows():\n",
    "            species = row[\"species\"]\n",
    "            cc, td = Localizer._get_cross_correlations(\n",
    "                reference_file=row[\"reference_file\"],\n",
    "                other_files=row[\"other_files\"],\n",
    "                start_time=row[\"time\"][0],\n",
    "                end_time=row[\"time\"][1],\n",
    "                bandpass_range=self.bandpass_ranges[species],\n",
    "                max_delay=self.max_delay,\n",
    "                SAMPLE_RATE=44100,\n",
    "            )\n",
    "            all_ccs.append(cc)\n",
    "            all_tds.append(td)\n",
    "        self.cross_correlations = self.detections.copy()\n",
    "        self.cross_correlations[\"cross_correlations\"] = all_ccs\n",
    "        self.cross_correlations[\"time_delays\"] = all_tds\n",
    "        return self.cross_correlations\n",
    "\n",
    "    def filter_cross_correlations(self):\n",
    "        # filter the cross correlations\n",
    "        # return a pandas dataframe with the results\n",
    "        if self.cross_correlations is None:\n",
    "            print(\"No cross correlations exist - running cross_correlate\")\n",
    "            self.cross_correlate()\n",
    "        # filter the cross-correlations\n",
    "        above_threshold = [\n",
    "            cc > self.cc_threshold\n",
    "            for cc in self.cross_correlations[\"cross_correlations\"]\n",
    "        ]\n",
    "\n",
    "        n_before = len(self.cross_correlations)  # number of rows before filtering\n",
    "\n",
    "        filtered_ccs = []\n",
    "        filtered_files = []\n",
    "        filtered_tdoas = []\n",
    "        for i in range(len(self.cross_correlations)):\n",
    "            mask = above_threshold[i]\n",
    "            cc = self.cross_correlations[\"cross_correlations\"].iloc[i]\n",
    "            other_files = np.array(self.cross_correlations[\"other_files\"].iloc[i])\n",
    "            tdoa = np.array(self.cross_correlations[\"time_delays\"].iloc[i])\n",
    "\n",
    "            filtered_ccs.append(cc[mask])\n",
    "            filtered_files.append(other_files[mask])\n",
    "            filtered_tdoas.append(tdoa[mask])\n",
    "\n",
    "        filtered_cross_correlations = self.cross_correlations.copy()\n",
    "\n",
    "        filtered_cross_correlations[\"cross_correlations\"] = filtered_ccs\n",
    "        filtered_cross_correlations[\"other_files\"] = filtered_files\n",
    "        filtered_cross_correlations[\"time_delays\"] = filtered_tdoas\n",
    "\n",
    "        # Filter by the cc scores. If less than min_number_of_receivers have cc_score above threshold, drop them.\n",
    "        ccs = [\n",
    "            np.array(scores)\n",
    "            for scores in filtered_cross_correlations[\"cross_correlations\"]\n",
    "        ]\n",
    "        num_ccs_above_threshold = [sum(a > self.cc_threshold) for a in ccs]\n",
    "        mask = np.array(num_ccs_above_threshold) >= self.min_number_of_receivers - 1\n",
    "        filtered_cross_correlations = filtered_cross_correlations[mask]\n",
    "\n",
    "        n_after = len(filtered_cross_correlations)  # number of rows after filtering\n",
    "        print(f\"{n_before - n_after} rows deleted\")\n",
    "        self.filtered_cross_correlations = filtered_cross_correlations\n",
    "        return filtered_cross_correlations\n",
    "\n",
    "    def localize(self,algorithm=\"gillette\"):\n",
    "        # localize the detections\n",
    "        # return a pandas dataframe with the results\n",
    "        # TODO: make work for 3d\n",
    "\n",
    "        localized = self.filtered_cross_correlations.copy()\n",
    "        locations = []\n",
    "        if self.filtered_cross_correlations is None:\n",
    "            print(\n",
    "                \"No filtered cross_correlations exist - running filter_cross_correlations\"\n",
    "            )\n",
    "            self.filter_cross_correlations()\n",
    "        if algorithm == \"gillette\":\n",
    "            # localize using gillette\n",
    "\n",
    "            for index, row in self.filtered_cross_correlations.iterrows():\n",
    "                reference = row[\"reference_file\"]\n",
    "                others = row[\"other_files\"]\n",
    "                reference_coords = self.aru_coords.loc[reference]\n",
    "                others_coords = [self.aru_coords.loc[i] for i in others]\n",
    "                all_coords = [reference_coords] + others_coords\n",
    "                # add 0 tdoa for reference receiver\n",
    "                delays = np.insert(row[\"time_delays\"], 0, 0)\n",
    "\n",
    "                location, _, _ = gillette_localize(all_coords, delays)\n",
    "                locations.append(location)\n",
    "            localized[\"predicted_x\"] = [locations[i][0] for i in range(len(locations))]\n",
    "            localized[\"predicted_y\"] = [locations[i][1] for i in range(len(locations))]\n",
    "            localized[\"gillette_error\"] = [\"Error\" for i in range(len(locations))]\n",
    "        elif algorithm == \"soundfinder\":\n",
    "\n",
    "            for index, row in self.filtered_cross_correlations.iterrows():\n",
    "                reference = row[\"reference_file\"]\n",
    "                others = row[\"other_files\"]\n",
    "                reference_coords = self.aru_coords.loc[reference]\n",
    "                others_coords = [self.aru_coords.loc[i] for i in others]\n",
    "                all_coords = [reference_coords] + others_coords\n",
    "                # add 0 tdoa for reference receiver\n",
    "                delays = np.insert(row[\"time_delays\"], 0, 0)\n",
    "\n",
    "                location = soundfinder(all_coords, delays)\n",
    "                locations.append(location)\n",
    "            localized[\"predicted_x\"] = [locations[i][0] for i in range(len(locations))]\n",
    "            localized[\"predicted_y\"] = [locations[i][1] for i in range(len(locations))]\n",
    "            localized[\"pseudorange_error\"] = [\n",
    "                locations[i][2] for i in range(len(locations))\n",
    "            ]\n",
    "        else:\n",
    "            raise UserWarning(\"Algorithm not recognized\")\n",
    "        self.locations = localized\n",
    "        return localized\n",
    "\n",
    "    def _get_cross_correlations(\n",
    "        reference_file,\n",
    "        other_files,\n",
    "        start_time,\n",
    "        end_time,\n",
    "        bandpass_range,\n",
    "        max_delay,\n",
    "        SAMPLE_RATE,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Gets the maximal cross correlations and the time-delay (in s) corresponding to that cross correlation between\n",
    "        the reference_file and other_files. Setting max_delay ensures that only cross-correlations\n",
    "        +/- a certain time-delay are returned. i.e if a sound can be a maximum of +/-\n",
    "        ----\n",
    "        args:\n",
    "            reference_file: Path to reference file.\n",
    "            other_files: List of paths to the other files which will be cross-correlated against reference_file\n",
    "            start_time: start of time segment (in seconds) to be cross-correlated\n",
    "            end_time: end of time segment (in seconds) to be cross-correlated.\n",
    "            bandpass_range: [lower, higher] of bandpass range.\n",
    "            max_delay: the maximum time (in seconds) to return cross_correlations for. i.e. if the best cross correlation\n",
    "                        occurs for a time-delay greater than max_delay, the function will not return it, instead it will return\n",
    "                        the maximal cross correlation within +/- max_delay\n",
    "            SAMPLE_RATE: the sampling rate of the audio.\n",
    "        returns:\n",
    "            ccs: list of maximal cross-correlations for each pair of files.\n",
    "            time_differences: list of time differences (in seconds) that yield the maximal cross-correlation.\n",
    "        \"\"\"\n",
    "        lower = min(bandpass_range)\n",
    "        higher = max(bandpass_range)\n",
    "\n",
    "        reference_audio = Audio.from_file(\n",
    "            reference_file, offset=start_time, duration=end_time - start_time\n",
    "        ).bandpass(lower, higher, order=9)\n",
    "        other_audio = [\n",
    "            Audio.from_file(\n",
    "                i, offset=start_time, duration=end_time - start_time\n",
    "            ).bandpass(lower, higher, order=9)\n",
    "            for i in other_files\n",
    "        ]\n",
    "\n",
    "        max_lag = int(\n",
    "            max_delay * SAMPLE_RATE\n",
    "        )  # Convert max_delay (in s) to max_lag in samples\n",
    "\n",
    "        ccs = np.zeros(len(other_audio))\n",
    "        time_difference = np.zeros(len(other_audio))\n",
    "        for index, audio_object in enumerate(other_audio):\n",
    "            ff = reference_audio.samples\n",
    "            sf = audio_object.samples\n",
    "\n",
    "            # TODO: Normalize these, so cross-correlation will return values -1<cc<1\n",
    "            # TODO: verify this makes sense, could there be some floating point issues with this? Is it the right kind\n",
    "            # of normalization\n",
    "            ff = ff / np.std(ff)\n",
    "            sf = sf / np.std(sf)\n",
    "\n",
    "            cc = correlate(ff, sf, mode=\"same\")  # correlations are per sample\n",
    "            cc /= min(len(ff), len(sf))\n",
    "            lags = correlation_lags(ff.size, sf.size, mode=\"same\")\n",
    "\n",
    "            # slice cc and lags, so we only look at cross_correlations that are between -max_lag and +max_lag\n",
    "            lower_limit = int(len(cc) / 2 - max_lag)\n",
    "            upper_limit = int(len(cc) / 2 + max_lag)\n",
    "\n",
    "            cc = cc[lower_limit:upper_limit]\n",
    "            lags = lags[lower_limit:upper_limit]\n",
    "\n",
    "            # from IPython.core.debugger import Pdb; Pdb().set_trace()\n",
    "            max_cc = np.max(cc)\n",
    "            lag = -lags[\n",
    "                np.argmax(cc)\n",
    "            ]  # in ties (>2 ccs with same max value), argmax returns the first.\n",
    "            time_difference[index] = lag\n",
    "            ccs[index] = max_cc\n",
    "        time_difference = [i / SAMPLE_RATE for i in time_difference]\n",
    "\n",
    "        return ccs, time_difference\n",
    "\n",
    "    def _get_detections(predictions_df, cnn_score_threshold):\n",
    "        \"\"\"\n",
    "        Takes the predictions_df of CNN scores *FOR A SINGLE SPECIES*, chooses only detections > cnn_score_threshold\n",
    "        and outputs a dictionary of times at which events were detected, and the ARU files they were detected in.\n",
    "        args:\n",
    "            predictions_array: a dataframe with multi-index of (file, start, end) with a column that is values for model predictions\n",
    "            *FOR A SINGLE SPECIES*\n",
    "            cnn_score_threshold: the minimum CNN score needed for a time-window to be considered a detection.\n",
    "        returns:\n",
    "            A dictionary of predictions, with key (start_time, end_time), and value list of files with detection triggered\n",
    "            e.g. {(0.0,2.0): [ARU_0.mp3. ARU_1.mp3]}\n",
    "        \"\"\"\n",
    "        # get the detections from the predictions\n",
    "        # Threshold the scores to above cnn_score_threshold\n",
    "        booleans = (\n",
    "            predictions_df.loc[:, :, :] > cnn_score_threshold\n",
    "        )  # find rows above threshold\n",
    "        indices = (\n",
    "            booleans[booleans].dropna().index\n",
    "        )  # choose just those rows. dropna required to drop the others\n",
    "        recorders = indices.get_level_values(\n",
    "            0\n",
    "        )  # get the list of recorders out of the multi-index\n",
    "        indices = indices.droplevel(level=0)  # drop the recorders\n",
    "\n",
    "        dataframe = pd.DataFrame(\n",
    "            data=recorders, index=indices\n",
    "        )  # df with index (start_time, end_time)\n",
    "        dataframe = (\n",
    "            dataframe.sort_index()\n",
    "        )  # done to ensure speed-up and not get performancewarning\n",
    "        recorders_list = []\n",
    "        for idx in dataframe.index.unique():\n",
    "            recorders_in_time = dataframe.loc[idx].values\n",
    "            recorders_in_time = [\n",
    "                i[0] for i in recorders_in_time\n",
    "            ]  # to get recorder path string out of numpy array\n",
    "            recorders_list.append(recorders_in_time)\n",
    "        return dict(zip(dataframe.index.unique(), recorders_list))\n",
    "\n",
    "    def _group_detections(detections, aru_coords, min_number_of_receivers, max_distance_between_receivers):\n",
    "        \"\"\"\n",
    "        Takes the detections dictionary and groups detections that are within max_distance_between_receivers of each other.\n",
    "        args:\n",
    "            detections: a dictionary of detections, with key (start_time, end_time), and value list of files with detection triggered\n",
    "            aru_coords: a dictionary of aru coordinates, with key aru file path, and value (x,y) coordinates\n",
    "            max_distance_between_receivers: the maximum distance between recorders to consider a detection as a single event\n",
    "        returns:\n",
    "            A dictionary of grouped detections, with key (start_time, end_time), and value list of files with detection triggered\n",
    "            e.g. {(0.0,2.0): [ARU_0.mp3. ARU_1.mp3]}\n",
    "        \"\"\"\n",
    "        # group detections that are within max_distance_between_receivers of each other\n",
    "        # return a dictionary of grouped detections\n",
    "        # get the coordinates of the recorders\n",
    "        # get the distance between recorders\n",
    "        # if the distance is less than max_distance_between_receivers, group the detections\n",
    "        from itertools import product\n",
    "\n",
    "        # Group recorders based on being within < max_distance_between_receivers.\n",
    "        # recorders_in_distance is dictionary in\n",
    "        # form {ARU_0.mp3: [ARU_1.mp3, ARU_2.mp3...] for all recorders within max_distance_between_receivers }\n",
    "        recorders_in_distance = dict()\n",
    "\n",
    "        aru_files = aru_coords.index\n",
    "        for aru in aru_files:  # loop over the aru files\n",
    "            pos_aru = np.array(aru_coords.loc[aru])\n",
    "            other_arus = np.array(aru_coords)\n",
    "            distances = other_arus - pos_aru\n",
    "            euclid_distances = [np.linalg.norm(d) for d in distances]\n",
    "\n",
    "            mask = [\n",
    "                0 < i <= max_distance_between_receivers for i in euclid_distances\n",
    "            ]  # boolean mask\n",
    "            recorders_in_distance[aru] = list(aru_files[mask])\n",
    "\n",
    "        times = []\n",
    "        reference_files = []\n",
    "        other_files = []\n",
    "\n",
    "        for time_segment in detections.keys():  # iterate through all the time-segments\n",
    "            for file in detections[\n",
    "                time_segment\n",
    "            ]:  # iterate through each file with a call detected in this time-segment\n",
    "                reference = file  # set this file to be reference\n",
    "                others = [\n",
    "                    f for f in detections[time_segment] if f != reference\n",
    "                ]  # All the other ARUs\n",
    "                others_in_distance = [\n",
    "                    aru for aru in others if aru in recorders_in_distance[reference]\n",
    "                ]  # ARUs close enough\n",
    "\n",
    "                if (\n",
    "                    len(others_in_distance) + 1 >= min_number_of_receivers\n",
    "                ):  # minimum number of ARUs needed to localize.\n",
    "                    times.append(time_segment)\n",
    "                    reference_files.append(reference)\n",
    "                    other_files.append(others_in_distance)\n",
    "\n",
    "        grouped_detections = pd.DataFrame(\n",
    "            data=zip(times, reference_files, other_files),\n",
    "            columns=[\"time\", \"reference_file\", \"other_files\"],\n",
    "        )\n",
    "        return grouped_detections\n",
    "\n",
    "\n",
    "def calc_speed_of_sound(temperature=20):\n",
    "    \"\"\"\n",
    "    Calculate speed of sound in meters per second\n",
    "\n",
    "    Calculate speed of sound for a given temperature\n",
    "    in Celsius (Humidity has a negligible\n",
    "    effect on speed of sound and so this functionality\n",
    "    is not implemented)\n",
    "\n",
    "    Args:\n",
    "        temperature: ambient temperature in Celsius\n",
    "\n",
    "    Returns:\n",
    "        the speed of sound in meters per second\n",
    "    \"\"\"\n",
    "    return 331.3 * np.sqrt(1 + float(temperature) / 273.15)\n",
    "\n",
    "\n",
    "def lorentz_ip(u, v=None):\n",
    "    \"\"\"\n",
    "    Compute Lorentz inner product of two vectors\n",
    "\n",
    "    For vectors `u` and `v`, the\n",
    "    Lorentz inner product for 3-dimensional case is defined as\n",
    "\n",
    "        u[0]*v[0] + u[1]*v[1] + u[2]*v[2] - u[3]*v[3]\n",
    "\n",
    "    Or, for 2-dimensional case as\n",
    "\n",
    "        u[0]*v[0] + u[1]*v[1] - u[2]*v[2]\n",
    "\n",
    "    Args:\n",
    "        u: vector with shape either (3,) or (4,)\n",
    "        v: vector with same shape as x1; if None (default), sets v = u\n",
    "\n",
    "    Returns:\n",
    "        float: value of Lorentz IP\"\"\"\n",
    "    if v is None:\n",
    "        v = u\n",
    "\n",
    "    if len(u) == 3 and len(v) == 3:\n",
    "        c = [1, 1, -1]\n",
    "        return sum([u[i] * v[i] * c[i] for i in range(len(u))])\n",
    "    elif len(u) == 4 and len(v) == 4:\n",
    "        c = [1, 1, 1, -1]\n",
    "        return sum([u[i] * v[i] * c[i] for i in range(len(u))])\n",
    "\n",
    "    return ValueError(f\"length of x should be 3 or 4, was{len(u)}\")\n",
    "\n",
    "\n",
    "def gillette_localize(\n",
    "    receivers=list,\n",
    "    delays=list,\n",
    "    temp=20,\n",
    "    m=[0],\n",
    "    exact=True,\n",
    "    summary=False,\n",
    "    confint=False,\n",
    "    alpha=0.05,\n",
    "    td_error=False,\n",
    "    total_td_error=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Calculate the estimated location of a sound's source using the\n",
    "    algorithm laid out in Gillette and Silverman (2008)\n",
    "    Args:\n",
    "        receivers: A numpy array of coordinates for microphones used to\n",
    "        record the sound. The number of microphones needed should\n",
    "        be two more than the dimensions being localized in. The\n",
    "        first row will be treated as a reference point for the\n",
    "        algorithm.\n",
    "        tdoa: A list of time delays. Each entry should be the time\n",
    "        delay for the corresponding item in the receivers list\n",
    "        (i.e. the first item is the delay for the first receiver).\n",
    "        The first item in this list should be 0, with all other\n",
    "        entries centered around that.\n",
    "        temp: ambient temperature in Celsius. Defaults to 20.\n",
    "        exact: computes an exact solution if True, computes estimates\n",
    "        with uncertainty if false. Defaults to True\n",
    "        summary: displays a summary of the estimates if True. Defaults\n",
    "        to false.\n",
    "        confint: outputs confidence intervals for the estimated\n",
    "        coordinates if true. Defaults to false.\n",
    "        alpha: Determines confidence level of the confidence intervals.\n",
    "        Defaults to 0.05.\n",
    "        m: the index of the reference mic. Defaults to 0.\n",
    "        td_error: Computes the expected time delay from the estimated\n",
    "        source location, centered around the reference mic, for each\n",
    "        microphone.\n",
    "        total_td_error: Computes the euclidean norm of the errors\n",
    "        provided by td_error.\n",
    "    Returns:\n",
    "        an array with the estimated coordinates and the estimated\n",
    "        distance from the reference mic. (One reference mic and two\n",
    "        additional mics, this is a 2 item array containing an estima\n",
    "        -ted x coordinate and a distance.)\n",
    "    \"\"\"\n",
    "    import opensoundscape.localization as loc\n",
    "    import statsmodels.api as sm\n",
    "\n",
    "    C = loc.calc_speed_of_sound(temperature=20)\n",
    "    # Compile know receiver locations and distance delays into an output vector\n",
    "    out_knowns = []\n",
    "    in_knowns = np.zeros(((len(receivers) - len(m)) * len(m), 2 + len(m)))\n",
    "    toa = np.array(delays)\n",
    "    r = 0\n",
    "    out_knowns = []\n",
    "    for k in range(len(m)):\n",
    "        tdoa = (\n",
    "            toa - toa[m[k]]\n",
    "        )  # Use the speed of sound to convert time delays to \"distance delays\"\n",
    "        diffs = []\n",
    "        for delay in tdoa:\n",
    "            diffs.append(float(delay * loc.calc_speed_of_sound(20)))\n",
    "        for i in range(len(receivers)):\n",
    "            if i in m:\n",
    "                continue\n",
    "            else:\n",
    "                w = diffs[i] ** 2\n",
    "                for j in range(len(receivers[i])):\n",
    "                    w = w - receivers[i][j] ** 2 + receivers[m[k]][j] ** 2\n",
    "                w = w / 2\n",
    "                out_knowns.append(w)\n",
    "        for i in range(len(receivers)):\n",
    "            if i in m:\n",
    "                continue\n",
    "            else:\n",
    "                q = 0\n",
    "                for j in range(len(receivers[i])):\n",
    "                    z = receivers[m[k]][j] - receivers[i][j]\n",
    "                    in_knowns[r][q] = z\n",
    "                    q += 1\n",
    "                in_knowns[r][q + k] = diffs[i]\n",
    "                r += 1\n",
    "                continue\n",
    "\n",
    "        # Using least squares, compute the final estimated location of source\n",
    "    location = sm.OLS(out_knowns, in_knowns).fit()\n",
    "    return (\n",
    "        location.params,\n",
    "        location.summary(alpha=alpha),\n",
    "        location.conf_int(alpha=alpha),\n",
    "    )\n",
    "    if summary == True:\n",
    "        return location.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test with a model\n",
    "from opensoundscape.torch.models.cnn import CNN\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "specky_table = pd.read_csv(Path(\"woodcock_labeled_data/woodcock_labels.csv\"))\n",
    "from sklearn.model_selection import train_test_split\n",
    "# create a new dataframe with the filenames from the previous table as the index\n",
    "labels = pd.DataFrame(index=specky_table['filename'])\n",
    "\n",
    "#convert 'present' to 1 and 'absent' to 0\n",
    "labels['woodcock']=[1 if l=='present' else 0 for l in specky_table['woodcock']]\n",
    "\n",
    "#look at the first rows\n",
    "labels.head(3)\n",
    "train_df,validation_df = train_test_split(labels,test_size=0.2,random_state=1)\n",
    "classes = train_df.columns #in this case, there's just one class: [\"woodcock\"]\n",
    "\n",
    "model = CNN('resnet18',classes=classes,sample_duration=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 4 required positional arguments: 'aru_coords', 'sample_rate', 'min_number_of_receivers', and 'max_distance_between_receivers'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_s/zm3gz4x52glfbflc25_3rp3w0000gq/T/ipykernel_22924/2982742998.py\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'./woodcock_labeled_data/'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLocalizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthresholds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"woodcock\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 4 required positional arguments: 'aru_coords', 'sample_rate', 'min_number_of_receivers', and 'max_distance_between_receivers'"
     ]
    }
   ],
   "source": [
    "files = ['./woodcock_labeled_data/' + i for i in labels.index]\n",
    "a = Localizer(model = model, files = files, thresholds = {\"woodcock\":2}, predictions = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_s/zm3gz4x52glfbflc25_3rp3w0000gq/T/ipykernel_22924/2713153795.py:33: FutureWarning: inplace is deprecated and will be removed in a future version.\n",
      "  preds.index.set_levels([str(i).replace(old_dir, new_dir) for i in preds.index.levels[0]], level=0, inplace=True)\n"
     ]
    }
   ],
   "source": [
    "### try with a real example\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "from opensoundscape.torch.models.cnn import load_model\n",
    "import pandas as pd\n",
    "folder = Path(\"/Users/LOF19/Documents/kitzes_projects/LOCA_class/LOCA22_rotation/classifier/2022_10_06/\")\n",
    "aru_coords = pd.read_csv(folder / \"aru_coords.csv\", index_col=0)\n",
    "SAMPLE_RATE = 44100\n",
    "\n",
    "model = load_model(folder / \"models/best.model\")\n",
    "files = list(Path(\"/Users/LOF19/Documents/kitzes_projects/LOCA_class/LOCA22_rotation/synchronized\").glob(\"*/*.WAV\"))\n",
    "\n",
    "loca_class = Localizer(aru_coords=aru_coords, \n",
    "    sample_rate=44100, \n",
    "    min_number_of_receivers=4, \n",
    "    model=model, \n",
    "    files=files, \n",
    "    max_distance_between_receivers=150,\n",
    "    bandpass_ranges={\"COYE\":(1000, 10000), \"NOT_COYE\" : (1000, 10000)},\n",
    "    max_delay=0.5,\n",
    "    cc_threshold=0.05,\n",
    "    thresholds= {\"COYE\":0.5, \"NOT_COYE\": 100})\n",
    "\n",
    "preds = pd.read_csv(folder / \"preds.csv\", index_col=[0,1,2])\n",
    "\n",
    "# Moved files from snowy so\n",
    "# change paths to files\n",
    "old_dir = \"/home/lfh/projects/loca/LOCA22_rotation/synchronized/\"\n",
    "new_dir = \"/Users/LOF19/Documents/kitzes_projects/LOCA_class/LOCA22_rotation/synchronized/\"\n",
    "\n",
    "aru_coords.index = [str(i).replace(old_dir, new_dir) for i in aru_coords.index] \n",
    "preds.index.set_levels([str(i).replace(old_dir, new_dir) for i in preds.index.levels[0]], level=0, inplace=True) \n",
    "\n",
    "# set preds so they don't have to be re-calculated\n",
    "loca_class.predictions = preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "ename": "UserWarning",
     "evalue": "Predictions already exist - set predictions to None if you want to re-run predictions",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUserWarning\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/_s/zm3gz4x52glfbflc25_3rp3w0000gq/T/ipykernel_22924/1214914341.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloca_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/var/folders/_s/zm3gz4x52glfbflc25_3rp3w0000gq/T/ipykernel_22924/1446591122.py\u001b[0m in \u001b[0;36mget_predictions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    111\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_layer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    112\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m             raise UserWarning(\n\u001b[0m\u001b[1;32m    114\u001b[0m                 \u001b[0;34m\"Predictions already exist - set predictions to None if you want to re-run predictions\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m             )\n",
      "\u001b[0;31mUserWarning\u001b[0m: Predictions already exist - set predictions to None if you want to re-run predictions"
     ]
    }
   ],
   "source": [
    "preds = loca_class.get_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>reference_file</th>\n",
       "      <th>other_files</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(426.0, 429.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(426.0, 429.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(426.0, 429.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(426.0, 429.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(2334.0, 2337.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(2334.0, 2337.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(2334.0, 2337.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(2973.0, 2976.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2973.0, 2976.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2973.0, 2976.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2973.0, 2976.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                time                                     reference_file  \\\n",
       "0     (426.0, 429.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "1     (426.0, 429.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "2     (426.0, 429.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "3     (426.0, 429.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "4   (2334.0, 2337.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "5   (2334.0, 2337.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "6   (2334.0, 2337.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "7   (2973.0, 2976.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "8   (2973.0, 2976.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "9   (2973.0, 2976.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "10  (2973.0, 2976.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "\n",
       "                                          other_files species  \n",
       "0   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE  \n",
       "1   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE  \n",
       "2   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE  \n",
       "3   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE  \n",
       "4   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE  \n",
       "5   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE  \n",
       "6   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE  \n",
       "7   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE  \n",
       "8   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE  \n",
       "9   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE  \n",
       "10  [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE  "
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loca_class.threshold_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>reference_file</th>\n",
       "      <th>other_files</th>\n",
       "      <th>species</th>\n",
       "      <th>cross_correlations</th>\n",
       "      <th>time_delays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(426.0, 429.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.03515420854091644, 0.48581305146217346, 0.2...</td>\n",
       "      <td>[0.13854875283446713, -0.07095238095238095, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(426.0, 429.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.03515421226620674, 0.05400271713733673, 0.0...</td>\n",
       "      <td>[-0.13854875283446713, -0.21072562358276645, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(426.0, 429.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.48581305146217346, 0.05400271713733673, 0.3...</td>\n",
       "      <td>[0.07095238095238095, 0.21072562358276645, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(426.0, 429.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.2719675898551941, 0.029733862727880478, 0.3...</td>\n",
       "      <td>[0.04217687074829932, 0.18217687074829933, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(2334.0, 2337.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.010077455081045628, 0.01031660195440054, 0....</td>\n",
       "      <td>[0.35217687074829934, 0.06532879818594105, 0.4...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>(2334.0, 2337.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.010077453218400478, 0.02066768892109394, 0....</td>\n",
       "      <td>[-0.35217687074829934, -0.14485260770975056, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>(2334.0, 2337.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.01518901064991951, 0.04033719003200531, 0.0...</td>\n",
       "      <td>[-0.4819727891156463, -0.14267573696145125, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(2973.0, 2976.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.3562374711036682, 0.31654757261276245, 0.28...</td>\n",
       "      <td>[0.1299092970521542, -0.01748299319727891, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2973.0, 2976.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.3562374413013458, 0.3814222514629364, 0.307...</td>\n",
       "      <td>[-0.1299092970521542, -0.14736961451247166, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2973.0, 2976.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.31654754281044006, 0.381422221660614, 0.209...</td>\n",
       "      <td>[0.01748299319727891, 0.14736961451247166, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2973.0, 2976.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.289597749710083, 0.3078821897506714, 0.2092...</td>\n",
       "      <td>[-0.05916099773242631, 0.0707482993197279, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                time                                     reference_file  \\\n",
       "0     (426.0, 429.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "1     (426.0, 429.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "2     (426.0, 429.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "3     (426.0, 429.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "4   (2334.0, 2337.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "5   (2334.0, 2337.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "6   (2334.0, 2337.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "7   (2973.0, 2976.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "8   (2973.0, 2976.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "9   (2973.0, 2976.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "10  (2973.0, 2976.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "\n",
       "                                          other_files species  \\\n",
       "0   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "1   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "2   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "3   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "4   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "5   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "6   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "7   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "8   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "9   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "10  [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "\n",
       "                                   cross_correlations  \\\n",
       "0   [0.03515420854091644, 0.48581305146217346, 0.2...   \n",
       "1   [0.03515421226620674, 0.05400271713733673, 0.0...   \n",
       "2   [0.48581305146217346, 0.05400271713733673, 0.3...   \n",
       "3   [0.2719675898551941, 0.029733862727880478, 0.3...   \n",
       "4   [0.010077455081045628, 0.01031660195440054, 0....   \n",
       "5   [0.010077453218400478, 0.02066768892109394, 0....   \n",
       "6   [0.01518901064991951, 0.04033719003200531, 0.0...   \n",
       "7   [0.3562374711036682, 0.31654757261276245, 0.28...   \n",
       "8   [0.3562374413013458, 0.3814222514629364, 0.307...   \n",
       "9   [0.31654754281044006, 0.381422221660614, 0.209...   \n",
       "10  [0.289597749710083, 0.3078821897506714, 0.2092...   \n",
       "\n",
       "                                          time_delays  \n",
       "0   [0.13854875283446713, -0.07095238095238095, -0...  \n",
       "1   [-0.13854875283446713, -0.21072562358276645, -...  \n",
       "2   [0.07095238095238095, 0.21072562358276645, 0.0...  \n",
       "3   [0.04217687074829932, 0.18217687074829933, -0....  \n",
       "4   [0.35217687074829934, 0.06532879818594105, 0.4...  \n",
       "5   [-0.35217687074829934, -0.14485260770975056, 0...  \n",
       "6   [-0.4819727891156463, -0.14267573696145125, -0...  \n",
       "7   [0.1299092970521542, -0.01748299319727891, 0.0...  \n",
       "8   [-0.1299092970521542, -0.14736961451247166, -0...  \n",
       "9   [0.01748299319727891, 0.14736961451247166, 0.0...  \n",
       "10  [-0.05916099773242631, 0.0707482993197279, -0....  "
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loca_class.cross_correlate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6 rows deleted\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>reference_file</th>\n",
       "      <th>other_files</th>\n",
       "      <th>species</th>\n",
       "      <th>cross_correlations</th>\n",
       "      <th>time_delays</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(426.0, 429.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.48581305146217346, 0.05400271713733673, 0.3...</td>\n",
       "      <td>[0.07095238095238095, 0.21072562358276645, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(2973.0, 2976.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.3562374711036682, 0.31654757261276245, 0.28...</td>\n",
       "      <td>[0.1299092970521542, -0.01748299319727891, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2973.0, 2976.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.3562374413013458, 0.3814222514629364, 0.307...</td>\n",
       "      <td>[-0.1299092970521542, -0.14736961451247166, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2973.0, 2976.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.31654754281044006, 0.381422221660614, 0.209...</td>\n",
       "      <td>[0.01748299319727891, 0.14736961451247166, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2973.0, 2976.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.289597749710083, 0.3078821897506714, 0.2092...</td>\n",
       "      <td>[-0.05916099773242631, 0.0707482993197279, -0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                time                                     reference_file  \\\n",
       "2     (426.0, 429.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "7   (2973.0, 2976.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "8   (2973.0, 2976.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "9   (2973.0, 2976.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "10  (2973.0, 2976.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "\n",
       "                                          other_files species  \\\n",
       "2   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "7   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "8   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "9   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "10  [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "\n",
       "                                   cross_correlations  \\\n",
       "2   [0.48581305146217346, 0.05400271713733673, 0.3...   \n",
       "7   [0.3562374711036682, 0.31654757261276245, 0.28...   \n",
       "8   [0.3562374413013458, 0.3814222514629364, 0.307...   \n",
       "9   [0.31654754281044006, 0.381422221660614, 0.209...   \n",
       "10  [0.289597749710083, 0.3078821897506714, 0.2092...   \n",
       "\n",
       "                                          time_delays  \n",
       "2   [0.07095238095238095, 0.21072562358276645, 0.0...  \n",
       "7   [0.1299092970521542, -0.01748299319727891, 0.0...  \n",
       "8   [-0.1299092970521542, -0.14736961451247166, -0...  \n",
       "9   [0.01748299319727891, 0.14736961451247166, 0.0...  \n",
       "10  [-0.05916099773242631, 0.0707482993197279, -0....  "
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loca_class.filter_cross_correlations()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1765: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1765: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1687: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1765: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1765: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1687: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1765: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1765: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1687: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1765: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1765: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1687: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/stats/stattools.py:74: ValueWarning: omni_normtest is not valid with less than 8 observations; 3 samples were given.\n",
      "  warn(\"omni_normtest is not valid with less than 8 observations; %i \"\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1765: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1765: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return 1 - (np.divide(self.nobs - self.k_constant, self.df_resid)\n",
      "/opt/anaconda3/envs/poetry_py39/lib/python3.9/site-packages/statsmodels/regression/linear_model.py:1687: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.dot(wresid, wresid) / self.df_resid\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time</th>\n",
       "      <th>reference_file</th>\n",
       "      <th>other_files</th>\n",
       "      <th>species</th>\n",
       "      <th>cross_correlations</th>\n",
       "      <th>time_delays</th>\n",
       "      <th>predicted_x</th>\n",
       "      <th>predicted_y</th>\n",
       "      <th>gillette_error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(426.0, 429.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.48581305146217346, 0.05400271713733673, 0.3...</td>\n",
       "      <td>[0.07095238095238095, 0.21072562358276645, 0.0...</td>\n",
       "      <td>665105.738125</td>\n",
       "      <td>4.461508e+06</td>\n",
       "      <td>Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(2973.0, 2976.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.3562374711036682, 0.31654757261276245, 0.28...</td>\n",
       "      <td>[0.1299092970521542, -0.01748299319727891, 0.0...</td>\n",
       "      <td>665096.157565</td>\n",
       "      <td>4.461510e+06</td>\n",
       "      <td>Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>(2973.0, 2976.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.3562374413013458, 0.3814222514629364, 0.307...</td>\n",
       "      <td>[-0.1299092970521542, -0.14736961451247166, -0...</td>\n",
       "      <td>665096.158288</td>\n",
       "      <td>4.461510e+06</td>\n",
       "      <td>Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>(2973.0, 2976.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.31654754281044006, 0.381422221660614, 0.209...</td>\n",
       "      <td>[0.01748299319727891, 0.14736961451247166, 0.0...</td>\n",
       "      <td>665096.158207</td>\n",
       "      <td>4.461510e+06</td>\n",
       "      <td>Error</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>(2973.0, 2976.0)</td>\n",
       "      <td>/Users/LOF19/Documents/kitzes_projects/LOCA_cl...</td>\n",
       "      <td>[/Users/LOF19/Documents/kitzes_projects/LOCA_c...</td>\n",
       "      <td>COYE</td>\n",
       "      <td>[0.289597749710083, 0.3078821897506714, 0.2092...</td>\n",
       "      <td>[-0.05916099773242631, 0.0707482993197279, -0....</td>\n",
       "      <td>665096.158287</td>\n",
       "      <td>4.461510e+06</td>\n",
       "      <td>Error</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                time                                     reference_file  \\\n",
       "2     (426.0, 429.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "7   (2973.0, 2976.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "8   (2973.0, 2976.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "9   (2973.0, 2976.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "10  (2973.0, 2976.0)  /Users/LOF19/Documents/kitzes_projects/LOCA_cl...   \n",
       "\n",
       "                                          other_files species  \\\n",
       "2   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "7   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "8   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "9   [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "10  [/Users/LOF19/Documents/kitzes_projects/LOCA_c...    COYE   \n",
       "\n",
       "                                   cross_correlations  \\\n",
       "2   [0.48581305146217346, 0.05400271713733673, 0.3...   \n",
       "7   [0.3562374711036682, 0.31654757261276245, 0.28...   \n",
       "8   [0.3562374413013458, 0.3814222514629364, 0.307...   \n",
       "9   [0.31654754281044006, 0.381422221660614, 0.209...   \n",
       "10  [0.289597749710083, 0.3078821897506714, 0.2092...   \n",
       "\n",
       "                                          time_delays    predicted_x  \\\n",
       "2   [0.07095238095238095, 0.21072562358276645, 0.0...  665105.738125   \n",
       "7   [0.1299092970521542, -0.01748299319727891, 0.0...  665096.157565   \n",
       "8   [-0.1299092970521542, -0.14736961451247166, -0...  665096.158288   \n",
       "9   [0.01748299319727891, 0.14736961451247166, 0.0...  665096.158207   \n",
       "10  [-0.05916099773242631, 0.0707482993197279, -0....  665096.158287   \n",
       "\n",
       "     predicted_y gillette_error  \n",
       "2   4.461508e+06          Error  \n",
       "7   4.461510e+06          Error  \n",
       "8   4.461510e+06          Error  \n",
       "9   4.461510e+06          Error  \n",
       "10  4.461510e+06          Error  "
      ]
     },
     "execution_count": 182,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loca_class.localize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 3, 3, 3, 3]"
      ]
     },
     "execution_count": 183,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[len(x) for x in loca_class.locations[\"cross_correlations\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "poetry_py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08ab727aedfeba4fe73c824599cc434fa16daf5621471b3748990173d78fc895"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
